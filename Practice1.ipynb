{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a23288-ed16-47e8-b044-aa152b40ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4f966-931b-40df-80f6-48bd356813fd",
   "metadata": {},
   "source": [
    "## Getting the required Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d910b9bf-c164-4dc3-8ebb-d3057b305ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hardi\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e293c843-d3de-4dc2-bb3b-064fb609b932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa5ee79-d6f9-4c2f-93e6-0b9177d1dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words(\"shakespeare-hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8978d9-795f-494c-ba14-40852a744a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfaa93b3-697a-4d3e-ac84-f3954e229399",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = \"\"\"Data science is the domain of study that deals with vast volumes of data using modern tools and techniques to find unseen patterns, derive meaningful information, and make business decisions. Data science uses complex machine learning algorithms to build predictive models.\n",
    "\n",
    "The data used for analysis can come from many different sources and presented in various formats.\n",
    "\n",
    "Now that you know what data science is, let’s see why data science is essential to today’s IT landscape.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f9e00c-769a-448b-a2db-27df04874e8f",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3e73fc-5742-405e-b34b-3f1bde0f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8bcdc7-d40c-44ff-b406-4bcb8e4f3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_tokens = word_tokenize(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edbc56a-4142-4128-a42a-03d280e6f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b424b44-390d-497c-96f4-f3c57dc3e5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'data': 6, 'science': 4, '.': 4, 'is': 3, 'and': 3, 'to': 3, ',': 3, 'the': 2, 'of': 2, 'that': 2, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in DS_tokens:\n",
    "    fdist[word.lower()] += 1\n",
    "    \n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220c437e-b97f-4c3f-a534-fed23b950419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is the domain of study that deals with vast volumes of data using modern tools and techniques to find unseen patterns, derive meaningful information, and make business decisions. Data science uses complex machine learning algorithms to build predictive models.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Blankline is used to separate the text by paragraphs if it has paragraphs\n",
    "\n",
    "from nltk.tokenize import blankline_tokenize\n",
    "\n",
    "blnk = blankline_tokenize(DS)\n",
    "blnk[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978798dc-f994-47cb-857e-1c107e4e201e",
   "metadata": {},
   "source": [
    "#### Tokenize by n number of words\n",
    "\n",
    "Bigrams, trigrams, ngrams tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212499b9-6cce-4279-9266-6e53703c1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a574450a-0dea-4f3f-a16b-b08ce9b1eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_toks = list(nltk.bigrams(DS_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fae8c5c-ea40-4144-b687-16016c396c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'science'),\n",
       " ('science', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'domain'),\n",
       " ('domain', 'of'),\n",
       " ('of', 'study'),\n",
       " ('study', 'that'),\n",
       " ('that', 'deals'),\n",
       " ('deals', 'with'),\n",
       " ('with', 'vast'),\n",
       " ('vast', 'volumes'),\n",
       " ('volumes', 'of'),\n",
       " ('of', 'data'),\n",
       " ('data', 'using'),\n",
       " ('using', 'modern'),\n",
       " ('modern', 'tools'),\n",
       " ('tools', 'and'),\n",
       " ('and', 'techniques'),\n",
       " ('techniques', 'to'),\n",
       " ('to', 'find'),\n",
       " ('find', 'unseen'),\n",
       " ('unseen', 'patterns'),\n",
       " ('patterns', ','),\n",
       " (',', 'derive'),\n",
       " ('derive', 'meaningful'),\n",
       " ('meaningful', 'information'),\n",
       " ('information', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'make'),\n",
       " ('make', 'business'),\n",
       " ('business', 'decisions'),\n",
       " ('decisions', '.'),\n",
       " ('.', 'Data'),\n",
       " ('Data', 'science'),\n",
       " ('science', 'uses'),\n",
       " ('uses', 'complex'),\n",
       " ('complex', 'machine'),\n",
       " ('machine', 'learning'),\n",
       " ('learning', 'algorithms'),\n",
       " ('algorithms', 'to'),\n",
       " ('to', 'build'),\n",
       " ('build', 'predictive'),\n",
       " ('predictive', 'models'),\n",
       " ('models', '.'),\n",
       " ('.', 'The'),\n",
       " ('The', 'data'),\n",
       " ('data', 'used'),\n",
       " ('used', 'for'),\n",
       " ('for', 'analysis'),\n",
       " ('analysis', 'can'),\n",
       " ('can', 'come'),\n",
       " ('come', 'from'),\n",
       " ('from', 'many'),\n",
       " ('many', 'different'),\n",
       " ('different', 'sources'),\n",
       " ('sources', 'and'),\n",
       " ('and', 'presented'),\n",
       " ('presented', 'in'),\n",
       " ('in', 'various'),\n",
       " ('various', 'formats'),\n",
       " ('formats', '.'),\n",
       " ('.', 'Now'),\n",
       " ('Now', 'that'),\n",
       " ('that', 'you'),\n",
       " ('you', 'know'),\n",
       " ('know', 'what'),\n",
       " ('what', 'data'),\n",
       " ('data', 'science'),\n",
       " ('science', 'is'),\n",
       " ('is', ','),\n",
       " (',', 'let'),\n",
       " ('let', '’'),\n",
       " ('’', 's'),\n",
       " ('s', 'see'),\n",
       " ('see', 'why'),\n",
       " ('why', 'data'),\n",
       " ('data', 'science'),\n",
       " ('science', 'is'),\n",
       " ('is', 'essential'),\n",
       " ('essential', 'to'),\n",
       " ('to', 'today'),\n",
       " ('today', '’'),\n",
       " ('’', 's'),\n",
       " ('s', 'IT'),\n",
       " ('IT', 'landscape'),\n",
       " ('landscape', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42489154-3bb5-477b-932a-2efc8fb5b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarly for trigrams\n",
    "\n",
    "trigrams_toks = list(nltk.trigrams(DS_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb76b75-bd64-488a-b0ea-47d754b3c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_toks = list(nltk.ngrams(DS_tokens, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3043a47-056c-41a9-8636-29ad08ba62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'science', 'is', 'the', 'domain'),\n",
       " ('science', 'is', 'the', 'domain', 'of'),\n",
       " ('is', 'the', 'domain', 'of', 'study'),\n",
       " ('the', 'domain', 'of', 'study', 'that'),\n",
       " ('domain', 'of', 'study', 'that', 'deals'),\n",
       " ('of', 'study', 'that', 'deals', 'with'),\n",
       " ('study', 'that', 'deals', 'with', 'vast'),\n",
       " ('that', 'deals', 'with', 'vast', 'volumes'),\n",
       " ('deals', 'with', 'vast', 'volumes', 'of'),\n",
       " ('with', 'vast', 'volumes', 'of', 'data'),\n",
       " ('vast', 'volumes', 'of', 'data', 'using'),\n",
       " ('volumes', 'of', 'data', 'using', 'modern'),\n",
       " ('of', 'data', 'using', 'modern', 'tools'),\n",
       " ('data', 'using', 'modern', 'tools', 'and'),\n",
       " ('using', 'modern', 'tools', 'and', 'techniques'),\n",
       " ('modern', 'tools', 'and', 'techniques', 'to'),\n",
       " ('tools', 'and', 'techniques', 'to', 'find'),\n",
       " ('and', 'techniques', 'to', 'find', 'unseen'),\n",
       " ('techniques', 'to', 'find', 'unseen', 'patterns'),\n",
       " ('to', 'find', 'unseen', 'patterns', ','),\n",
       " ('find', 'unseen', 'patterns', ',', 'derive'),\n",
       " ('unseen', 'patterns', ',', 'derive', 'meaningful'),\n",
       " ('patterns', ',', 'derive', 'meaningful', 'information'),\n",
       " (',', 'derive', 'meaningful', 'information', ','),\n",
       " ('derive', 'meaningful', 'information', ',', 'and'),\n",
       " ('meaningful', 'information', ',', 'and', 'make'),\n",
       " ('information', ',', 'and', 'make', 'business'),\n",
       " (',', 'and', 'make', 'business', 'decisions'),\n",
       " ('and', 'make', 'business', 'decisions', '.'),\n",
       " ('make', 'business', 'decisions', '.', 'Data'),\n",
       " ('business', 'decisions', '.', 'Data', 'science'),\n",
       " ('decisions', '.', 'Data', 'science', 'uses'),\n",
       " ('.', 'Data', 'science', 'uses', 'complex'),\n",
       " ('Data', 'science', 'uses', 'complex', 'machine'),\n",
       " ('science', 'uses', 'complex', 'machine', 'learning'),\n",
       " ('uses', 'complex', 'machine', 'learning', 'algorithms'),\n",
       " ('complex', 'machine', 'learning', 'algorithms', 'to'),\n",
       " ('machine', 'learning', 'algorithms', 'to', 'build'),\n",
       " ('learning', 'algorithms', 'to', 'build', 'predictive'),\n",
       " ('algorithms', 'to', 'build', 'predictive', 'models'),\n",
       " ('to', 'build', 'predictive', 'models', '.'),\n",
       " ('build', 'predictive', 'models', '.', 'The'),\n",
       " ('predictive', 'models', '.', 'The', 'data'),\n",
       " ('models', '.', 'The', 'data', 'used'),\n",
       " ('.', 'The', 'data', 'used', 'for'),\n",
       " ('The', 'data', 'used', 'for', 'analysis'),\n",
       " ('data', 'used', 'for', 'analysis', 'can'),\n",
       " ('used', 'for', 'analysis', 'can', 'come'),\n",
       " ('for', 'analysis', 'can', 'come', 'from'),\n",
       " ('analysis', 'can', 'come', 'from', 'many'),\n",
       " ('can', 'come', 'from', 'many', 'different'),\n",
       " ('come', 'from', 'many', 'different', 'sources'),\n",
       " ('from', 'many', 'different', 'sources', 'and'),\n",
       " ('many', 'different', 'sources', 'and', 'presented'),\n",
       " ('different', 'sources', 'and', 'presented', 'in'),\n",
       " ('sources', 'and', 'presented', 'in', 'various'),\n",
       " ('and', 'presented', 'in', 'various', 'formats'),\n",
       " ('presented', 'in', 'various', 'formats', '.'),\n",
       " ('in', 'various', 'formats', '.', 'Now'),\n",
       " ('various', 'formats', '.', 'Now', 'that'),\n",
       " ('formats', '.', 'Now', 'that', 'you'),\n",
       " ('.', 'Now', 'that', 'you', 'know'),\n",
       " ('Now', 'that', 'you', 'know', 'what'),\n",
       " ('that', 'you', 'know', 'what', 'data'),\n",
       " ('you', 'know', 'what', 'data', 'science'),\n",
       " ('know', 'what', 'data', 'science', 'is'),\n",
       " ('what', 'data', 'science', 'is', ','),\n",
       " ('data', 'science', 'is', ',', 'let'),\n",
       " ('science', 'is', ',', 'let', '’'),\n",
       " ('is', ',', 'let', '’', 's'),\n",
       " (',', 'let', '’', 's', 'see'),\n",
       " ('let', '’', 's', 'see', 'why'),\n",
       " ('’', 's', 'see', 'why', 'data'),\n",
       " ('s', 'see', 'why', 'data', 'science'),\n",
       " ('see', 'why', 'data', 'science', 'is'),\n",
       " ('why', 'data', 'science', 'is', 'essential'),\n",
       " ('data', 'science', 'is', 'essential', 'to'),\n",
       " ('science', 'is', 'essential', 'to', 'today'),\n",
       " ('is', 'essential', 'to', 'today', '’'),\n",
       " ('essential', 'to', 'today', '’', 's'),\n",
       " ('to', 'today', '’', 's', 'IT'),\n",
       " ('today', '’', 's', 'IT', 'landscape'),\n",
       " ('’', 's', 'IT', 'landscape', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_toks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbb782-7f32-4c81-8a49-25b14351bad4",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is to find similar words which stems or originates from the same root word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "128fb259-0375-46c9-b146-ea88ce7b6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b144fa6-fa1a-4162-9759-0265b179652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f01d5c-843b-49b3-9290-2db56d3af88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "scienc\n",
      "is\n",
      "the\n",
      "domain\n",
      "of\n",
      "studi\n",
      "that\n",
      "deal\n",
      "with\n",
      "vast\n",
      "volum\n",
      "of\n",
      "data\n",
      "use\n",
      "modern\n",
      "tool\n",
      "and\n",
      "techniqu\n",
      "to\n",
      "find\n",
      "unseen\n",
      "pattern\n",
      ",\n",
      "deriv\n",
      "meaning\n",
      "inform\n",
      ",\n",
      "and\n",
      "make\n",
      "busi\n",
      "decis\n",
      ".\n",
      "data\n",
      "scienc\n",
      "use\n",
      "complex\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "to\n",
      "build\n",
      "predict\n",
      "model\n",
      ".\n",
      "the\n",
      "data\n",
      "use\n",
      "for\n",
      "analysi\n",
      "can\n",
      "come\n",
      "from\n",
      "mani\n",
      "differ\n",
      "sourc\n",
      "and\n",
      "present\n",
      "in\n",
      "variou\n",
      "format\n",
      ".\n",
      "now\n",
      "that\n",
      "you\n",
      "know\n",
      "what\n",
      "data\n",
      "scienc\n",
      "is\n",
      ",\n",
      "let\n",
      "’\n",
      "s\n",
      "see\n",
      "whi\n",
      "data\n",
      "scienc\n",
      "is\n",
      "essenti\n",
      "to\n",
      "today\n",
      "’\n",
      "s\n",
      "it\n",
      "landscap\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in DS_tokens:\n",
    "    print(st.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6aeb2-afb8-40b0-b295-145f4f2c9c7f",
   "metadata": {},
   "source": [
    "## Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cce2217-a572-46ff-8726-959a606c27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hardi\\anaconda3\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03b8559-2f26-4186-9fff-85e30a87f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df4f308-86b3-4724-a713-ca47ffdbf382",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bedd73e5-5c80-4570-b635-5ecaacb46c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noth'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"noth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2dac6-5f50-440e-88b5-6e6684e6ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
