{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-25T07:08:03.771460Z","iopub.execute_input":"2022-08-25T07:08:03.772185Z","iopub.status.idle":"2022-08-25T07:08:03.819837Z","shell.execute_reply.started":"2022-08-25T07:08:03.772079Z","shell.execute_reply":"2022-08-25T07:08:03.818404Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#imports\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:12:09.925792Z","iopub.execute_input":"2022-08-25T08:12:09.926391Z","iopub.status.idle":"2022-08-25T08:12:09.935930Z","shell.execute_reply.started":"2022-08-25T08:12:09.926341Z","shell.execute_reply":"2022-08-25T08:12:09.934389Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"data = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\", lines=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:08:12.226372Z","iopub.execute_input":"2022-08-25T07:08:12.226987Z","iopub.status.idle":"2022-08-25T07:08:12.557903Z","shell.execute_reply.started":"2022-08-25T07:08:12.226948Z","shell.execute_reply":"2022-08-25T07:08:12.556384Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:08:12.559534Z","iopub.execute_input":"2022-08-25T07:08:12.559976Z","iopub.status.idle":"2022-08-25T07:08:12.583990Z","shell.execute_reply.started":"2022-08-25T07:08:12.559937Z","shell.execute_reply":"2022-08-25T07:08:12.582753Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#define parameters\n\nvocab_size= 10000\nmax_length =100","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:14:51.261517Z","iopub.execute_input":"2022-08-25T08:14:51.261930Z","iopub.status.idle":"2022-08-25T08:14:51.267702Z","shell.execute_reply.started":"2022-08-25T08:14:51.261895Z","shell.execute_reply":"2022-08-25T08:14:51.266798Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#Instantiate tokenizer\ntokenizer  = Tokenizer(num_words = vocab_size,oov_token=\"<OOV>\")\n\n#fit the data om tokenizer\ntokenizer.fit_on_texts(data['headline'])","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:14:51.619630Z","iopub.execute_input":"2022-08-25T08:14:51.620045Z","iopub.status.idle":"2022-08-25T08:14:52.231939Z","shell.execute_reply.started":"2022-08-25T08:14:51.620008Z","shell.execute_reply":"2022-08-25T08:14:52.230865Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"#get the word index\nword_index = tokenizer.word_index\n\n#print length of word index\nprint(\"length of word index is \" + str(len(word_index)))\n\n#get the sequences\nsequences= tokenizer.texts_to_sequences(data['headline'])\n\n#pad sequences\npadded_seq = pad_sequences(sequences, padding=\"post\", maxlen=max_length, truncating=\"post\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:14:52.234010Z","iopub.execute_input":"2022-08-25T08:14:52.234405Z","iopub.status.idle":"2022-08-25T08:16:13.279641Z","shell.execute_reply.started":"2022-08-25T08:14:52.234370Z","shell.execute_reply":"2022-08-25T08:16:13.278273Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"#split the data\nX_train_nn, X_test_nn, y_train_nn, y_test_nn =  train_test_split(padded_seq, data['is_sarcastic'], test_size=0.2, random_state=4)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:16:13.281857Z","iopub.execute_input":"2022-08-25T08:16:13.282221Z","iopub.status.idle":"2022-08-25T08:16:13.294200Z","shell.execute_reply.started":"2022-08-25T08:16:13.282190Z","shell.execute_reply":"2022-08-25T08:16:13.293161Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"## Modeling using nueral networks","metadata":{}},{"cell_type":"code","source":"# create a model\nmodel = tf.keras.Sequential([\n    \n    tf.keras.layers.Embedding(vocab_size, 16, input_length=max_length),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(3, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# compile the model\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:16:13.295563Z","iopub.execute_input":"2022-08-25T08:16:13.296147Z","iopub.status.idle":"2022-08-25T08:16:13.343876Z","shell.execute_reply.started":"2022-08-25T08:16:13.296111Z","shell.execute_reply":"2022-08-25T08:16:13.342804Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"#fit the model\n\nmod = model.fit(X_train_nn, y_train_nn, epochs=10, validation_data=(X_test_nn, y_test_nn))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:16:13.346435Z","iopub.execute_input":"2022-08-25T08:16:13.346791Z","iopub.status.idle":"2022-08-25T08:16:45.534436Z","shell.execute_reply.started":"2022-08-25T08:16:13.346760Z","shell.execute_reply":"2022-08-25T08:16:45.533408Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"As we can see we are getting testing accuracy of 85.94% which is a good starting point, however, the model is currently overfitting because the training accuract is nearly 1. Let's visualize this. ","metadata":{}},{"cell_type":"code","source":"def plot_graphs(mod, string):\n    plt.plot(mod.history[string])\n    plt.plot(mod.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, \"val_\"+string])\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:22:53.250434Z","iopub.execute_input":"2022-08-25T08:22:53.250897Z","iopub.status.idle":"2022-08-25T08:22:53.258732Z","shell.execute_reply.started":"2022-08-25T08:22:53.250852Z","shell.execute_reply":"2022-08-25T08:22:53.257448Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"plot_graphs(mod, \"accuracy\")\nplot_graphs(mod, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-08-25T08:22:53.663872Z","iopub.execute_input":"2022-08-25T08:22:53.664313Z","iopub.status.idle":"2022-08-25T08:22:54.050850Z","shell.execute_reply.started":"2022-08-25T08:22:53.664275Z","shell.execute_reply":"2022-08-25T08:22:54.049711Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the word embedding in Tensorflow embedding Projector","metadata":{}},{"cell_type":"code","source":"# Get the embedding layer from the model (i.e. first layer)\nembedding_layer = model.layers[0]\n\n# Get the weights of the embedding layer\nembedding_weights = embedding_layer.get_weights()[0]\n\n# Print the shape. Expected is (vocab_size, embedding_dim)\nprint(embedding_weights.shape) \n\n# Get the index-word dictionary\nreverse_word_index = tokenizer.index_word","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:52:13.654933Z","iopub.execute_input":"2022-08-25T07:52:13.655387Z","iopub.status.idle":"2022-08-25T07:52:13.666674Z","shell.execute_reply.started":"2022-08-25T07:52:13.655349Z","shell.execute_reply":"2022-08-25T07:52:13.665278Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"import io\n\n# Open writeable files\nout_v = io.open('vecs.tsv', 'w', encoding='utf-8')\nout_m = io.open('meta.tsv', 'w', encoding='utf-8')\n\n# Initialize the loop. Start counting at `1` because `0` is just for the padding\nfor word_num in range(1, vocab_size):\n\n  # Get the word associated at the current index\n  word_name = reverse_word_index[word_num]\n\n  # Get the embedding weights associated with the current index\n  word_embedding = embedding_weights[word_num]\n\n  # Write the word name\n  out_m.write(word_name + \"\\n\")\n\n  # Write the word embedding\n  out_v.write('\\t'.join([str(x) for x in word_embedding]) + \"\\n\")\n\n# Close the files\nout_v.close()\nout_m.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:53:52.375512Z","iopub.execute_input":"2022-08-25T07:53:52.376350Z","iopub.status.idle":"2022-08-25T07:53:52.532397Z","shell.execute_reply.started":"2022-08-25T07:53:52.376307Z","shell.execute_reply":"2022-08-25T07:53:52.531340Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Import files utilities in Colab\ntry:\n    from google.colab import files\nexcept ImportError:\n    pass\n\n# Download the files\nelse:\n    files.download('vecs.tsv')\n    files.download('meta.tsv')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:54:26.630794Z","iopub.execute_input":"2022-08-25T07:54:26.631241Z","iopub.status.idle":"2022-08-25T07:54:26.637691Z","shell.execute_reply.started":"2022-08-25T07:54:26.631203Z","shell.execute_reply":"2022-08-25T07:54:26.636397Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Modeling Using Naive Bayes Algorithm","metadata":{}},{"cell_type":"code","source":"#vectorize the sentences data\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(data['headline']).toarray()\n\n#split the data\nX_train, X_test, y_train, y_test = train_test_split(X, data['is_sarcastic'], test_size=0.2, random_state=4)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:23:18.979590Z","iopub.execute_input":"2022-08-25T07:23:18.980306Z","iopub.status.idle":"2022-08-25T07:23:25.161408Z","shell.execute_reply.started":"2022-08-25T07:23:18.980255Z","shell.execute_reply":"2022-08-25T07:23:25.159960Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#initializ the model\nnb = MultinomialNB()\n\n#get the test accuracy\ny_test_predict = nb.fit(X_train, y_train).predict(X_test)\n\n#get the train accuracy\ny_train_predict = nb.fit(X_train, y_train).predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:08:20.165862Z","iopub.execute_input":"2022-08-25T07:08:20.166252Z","iopub.status.idle":"2022-08-25T07:08:24.825723Z","shell.execute_reply.started":"2022-08-25T07:08:20.166216Z","shell.execute_reply":"2022-08-25T07:08:24.824193Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the accuracy \nprint(f'Testing accuracy using Naive Bayes: {accuracy_score(y_test,y_test_predict)}')\n\nprint(f'Testing accuracy using Naive Bayes: {accuracy_score(y_train,y_train_predict)}')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:08:24.827876Z","iopub.execute_input":"2022-08-25T07:08:24.828980Z","iopub.status.idle":"2022-08-25T07:08:24.843617Z","shell.execute_reply.started":"2022-08-25T07:08:24.828918Z","shell.execute_reply":"2022-08-25T07:08:24.842296Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"\n## Modeling with Logistic regression\n\n","metadata":{}},{"cell_type":"code","source":"#create a model\nlr = LogisticRegression()\n\n#fit the data and predict\ny_test_pred_lr = lr.fit(X_train, y_train).predict(X_test)\n\n#predict for train data\ny_train_pred_lr = lr.fit(X_train, y_train).predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:08:24.846004Z","iopub.execute_input":"2022-08-25T07:08:24.847005Z","iopub.status.idle":"2022-08-25T07:09:21.959277Z","shell.execute_reply.started":"2022-08-25T07:08:24.846951Z","shell.execute_reply":"2022-08-25T07:09:21.955604Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(f'Testing accuracy using Logistic Regression: {accuracy_score(y_test,y_test_pred_lr)}')\n\nprint(f'Testing accuracy using Logistic Regression: {accuracy_score(y_train,y_train_pred_lr)}')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T07:10:44.188220Z","iopub.execute_input":"2022-08-25T07:10:44.188649Z","iopub.status.idle":"2022-08-25T07:10:44.199172Z","shell.execute_reply.started":"2022-08-25T07:10:44.188612Z","shell.execute_reply":"2022-08-25T07:10:44.198051Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n","metadata":{}},{"cell_type":"markdown","source":"We got higher accuracy using neural networks than Naive bayes and Logistic regression. However the nueral network model is overfitting with training accuracy nearly 1, which is not a good approach. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}